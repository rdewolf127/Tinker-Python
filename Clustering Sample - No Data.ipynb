{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Define the numeric features\n",
    "\n",
    "features = reporting[reporting.columns[7:26]]  #In this example these were consumer level metrics\n",
    "\n",
    "# Normalize the numeric features so they're on the same scale\n",
    "scaled_features = MinMaxScaler().fit_transform(features[reporting.columns[7:26]])\n",
    "\n",
    "# Get two principal components\n",
    "pca = PCA(n_components=2).fit(scaled_features)\n",
    "features_2d = pca.transform(scaled_features)\n",
    "features_2d[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(features_2d[:,0],features_2d[:,1])\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "# Create 10 models with 1 to 10 clusters\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i)\n",
    "    # Fit the data points\n",
    "    kmeans.fit(features.values)\n",
    "    # Get the WCSS (inertia) value\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    \n",
    "#Plot the WCSS values onto a line graph\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('WCSS by Clusters')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install kneed\n",
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looks like the correct number of clusters is 3, but lets check it programmatically\n",
    "k1 = KneeLocator(range(1, 11), wcss, curve=\"convex\", direction=\"decreasing\")\n",
    "k1.elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_coefficients = []\n",
    "for k in range(2, 11):\n",
    "   kmeans = KMeans(n_clusters=k,  init='k-means++', n_init=100, max_iter=1000)\n",
    "   kmeans.fit(scaled_features)\n",
    "   score = silhouette_score(scaled_features, kmeans.labels_)\n",
    "   silhouette_coefficients.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(2, 11), silhouette_coefficients)\n",
    "plt.xticks(range(2, 11))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a model based on 2 centroids\n",
    "model = KMeans(n_clusters=2, init='k-means++', n_init=100, max_iter=1000)\n",
    "# Fit to the data and predict the cluster assignments for each data point\n",
    "km_clusters = model.fit_predict(features.values)\n",
    "# View the cluster assignments\n",
    "km_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(samples, clusters):\n",
    "    col_dic = {0:'blue',1:'green',2:'orange', 3:'red',4:'black',5:'yellow',6:'brown', 7:'purple'}\n",
    "    mrk_dic = {0:'*',1:'x',2:'+',3:'o',4:'*',5:'x',6:'+',7:'o'}\n",
    "    colors = [col_dic[x] for x in clusters]\n",
    "    markers = [mrk_dic[x] for x in clusters]\n",
    "    for sample in range(len(clusters)):\n",
    "        plt.scatter(samples[sample][0], samples[sample][1], color = colors[sample], marker=markers[sample], s=100)\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2')\n",
    "    plt.title('Assignments')\n",
    "    plt.show()\n",
    "\n",
    "plot_clusters(features_2d, km_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thats a mess.  Lets try and agglomerative clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "agg_model = AgglomerativeClustering(n_clusters=2)\n",
    "agg_clusters = agg_model.fit_predict(features)\n",
    "agg_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(features_2d, agg_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Still overlapping.  Try DBSCAN\n",
    "from sklearn.cluster import DBSCAN\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_values = np.arange(8,12.75,0.25) # eps values to be investigated\n",
    "min_samples = np.arange(3,10) # min_samples values to be investigated\n",
    "DBSCAN_params = list(product(eps_values, min_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_clusters = []\n",
    "sil_score = []\n",
    "\n",
    "for p in DBSCAN_params:\n",
    "    DBS_clustering = DBSCAN(eps=p[0], min_samples=p[1]).fit(scaled_features)\n",
    "    no_of_clusters.append(len(np.unique(DBS_clustering.labels_)))\n",
    "    sil_score.append(silhouette_score(scaled_features, DBS_clustering.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame.from_records(DBSCAN_params, columns =['Eps', 'Min_samples'])   \n",
    "tmp['No_of_clusters'] = no_of_clusters\n",
    "\n",
    "pivot_1 = pd.pivot_table(tmp, values='No_of_clusters', index='Min_samples', columns='Eps')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "sns.heatmap(pivot_1, annot=True,annot_kws={\"size\": 16}, cmap=\"YlGnBu\", ax=ax)\n",
    "ax.set_title('Number of clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame.from_records(DBSCAN_params, columns =['Eps', 'Min_samples'])   \n",
    "tmp['Sil_score'] = sil_score\n",
    "\n",
    "pivot_1 = pd.pivot_table(tmp, values='Sil_score', index='Min_samples', columns='Eps')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "sns.heatmap(pivot_1, annot=True, annot_kws={\"size\": 10}, cmap=\"YlGnBu\", ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBS_clustering = DBSCAN(eps=12.5, min_samples=5).fit(scaled_features)\n",
    "\n",
    "DBSCAN_clustered = reporting.copy()\n",
    "DBSCAN_clustered.loc[:,'Cluster'] = DBS_clustering.labels_ # append labels to points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBSCAN_clust_sizes = DBSCAN_clustered.groupby('Cluster').size().to_frame()\n",
    "DBSCAN_clust_sizes.columns = [\"DBSCAN_size\"]\n",
    "DBSCAN_clust_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = DBSCAN_clustered[DBSCAN_clustered['Cluster']==-1]\n",
    "\n",
    "fig2, (axes) = plt.subplots(1,2,figsize=(12,5))\n",
    "\n",
    "\n",
    "sns.scatterplot('amount', 'eff_num_all_last_365',\n",
    "                data=DBSCAN_clustered[DBSCAN_clustered['Cluster']!=-1],\n",
    "                hue='Cluster', ax=axes[0], palette='Set1', legend='full', s=45)\n",
    "\n",
    "sns.scatterplot('amount', 'tot_ret_doll',\n",
    "                data=DBSCAN_clustered[DBSCAN_clustered['Cluster']!=-1],\n",
    "                hue='Cluster', palette='Set1', ax=axes[1], legend='full', s=45)\n",
    "\n",
    "axes[0].scatter(outliers['amount'], outliers['return_rate'], s=5, label='outliers', c=\"k\")\n",
    "axes[1].scatter(outliers['amount'], outliers['tot_ret_doll'], s=5, label='outliers', c=\"k\")\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "\n",
    "plt.setp(axes[0].get_legend().get_texts(), fontsize='10')\n",
    "plt.setp(axes[1].get_legend().get_texts(), fontsize='10')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
